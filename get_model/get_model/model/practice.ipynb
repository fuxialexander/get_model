{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "from typing import Optional, Any\n",
    "from inspect import isfunction\n",
    "\n",
    "try:\n",
    "    import xformers\n",
    "    import xformers.ops\n",
    "    XFORMERS_IS_AVAILBLE = True\n",
    "except:\n",
    "    XFORMERS_IS_AVAILBLE = False\n",
    "    print(\"No module 'xformers'. Proceeding without it.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exists(x):\n",
    "    return x is not None\n",
    "\n",
    "\n",
    "def default(val, d):\n",
    "    if exists(val):\n",
    "        return val\n",
    "    return d() if isfunction(d) else d\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, *, ch, out_ch, ch_mult=(1,2,4,8), num_res_blocks,\n",
    "                 attn_resolutions, dropout=0.0, resamp_with_conv=True, in_channels,\n",
    "                 resolution, z_channels, double_z=True, use_linear_attn=False, attn_type=\"vanilla\",\n",
    "                 **ignore_kwargs):\n",
    "        super().__init__()\n",
    "        if use_linear_attn: attn_type = \"linear\"\n",
    "        self.ch = ch\n",
    "        self.temb_ch = 0\n",
    "        self.num_resolutions = len(ch_mult)\n",
    "        self.num_res_blocks = num_res_blocks\n",
    "        self.resolution = resolution\n",
    "        self.in_channels = in_channels\n",
    "        # downsampling\n",
    "        self.conv_in = torch.nn.Conv2d(in_channels,\n",
    "                                       self.ch,\n",
    "                                       kernel_size=3,\n",
    "                                       stride=1,\n",
    "                                       padding=1)\n",
    "        curr_res = resolution\n",
    "        in_ch_mult = (1,)+tuple(ch_mult)\n",
    "        self.in_ch_mult = in_ch_mult\n",
    "        self.down = nn.ModuleList()\n",
    "        for i_level in range(self.num_resolutions):\n",
    "            block = nn.ModuleList()\n",
    "            attn = nn.ModuleList()\n",
    "            block_in = ch*in_ch_mult[i_level]\n",
    "            block_out = ch*ch_mult[i_level]\n",
    "            for i_block in range(self.num_res_blocks):\n",
    "                block.append(ResnetBlock(in_channels=block_in,\n",
    "                                         out_channels=block_out,\n",
    "                                         temb_channels=self.temb_ch,\n",
    "                                         dropout=dropout))\n",
    "                block_in = block_out\n",
    "                if curr_res in attn_resolutions:\n",
    "                    attn.append(make_attn(block_in, attn_type=attn_type))\n",
    "            down = nn.Module()\n",
    "            down.block = block\n",
    "            down.attn = attn\n",
    "            if i_level != self.num_resolutions-1:\n",
    "                down.downsample = Downsample(block_in, resamp_with_conv)\n",
    "                curr_res = curr_res // 2\n",
    "            self.down.append(down)\n",
    "        # middle\n",
    "        self.mid = nn.Module()\n",
    "        self.mid.block_1 = ResnetBlock(in_channels=block_in,\n",
    "                                       out_channels=block_in,\n",
    "                                       temb_channels=self.temb_ch,\n",
    "                                       dropout=dropout)\n",
    "        self.mid.attn_1 = make_attn(block_in, attn_type=attn_type)\n",
    "        self.mid.block_2 = ResnetBlock(in_channels=block_in,\n",
    "                                       out_channels=block_in,\n",
    "                                       temb_channels=self.temb_ch,\n",
    "                                       dropout=dropout)\n",
    "        # end\n",
    "        self.norm_out = Normalize(block_in)\n",
    "        self.conv_out = torch.nn.Conv2d(block_in,\n",
    "                                        2*z_channels if double_z else z_channels,\n",
    "                                        kernel_size=3,\n",
    "                                        stride=1,\n",
    "                                        padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # timestep embedding\n",
    "        print(\"Down is:\")\n",
    "        #print(self.down)\n",
    "        temb = None\n",
    "\n",
    "        # downsampling\n",
    "        hs = [self.conv_in(x)]\n",
    "        print(f\"After down sampling, hs is {len(hs)} {hs[0].shape}\")\n",
    "        for i_level in range(self.num_resolutions):\n",
    "            print(f\"level {i_level+1}/{self.num_resolutions}\")\n",
    "            for i_block in range(self.num_res_blocks):\n",
    "                print(f\"block {i_block+1}/{self.num_res_blocks}\")\n",
    "                h = self.down[i_level].block[i_block](hs[-1], temb)\n",
    "                if len(self.down[i_level].attn) > 0:\n",
    "                    h = self.down[i_level].attn[i_block](h)\n",
    "                hs.append(h)\n",
    "            if i_level != self.num_resolutions-1:\n",
    "                hs.append(self.down[i_level].downsample(hs[-1]))\n",
    "        print(f\"Now computing middle block1->attn1->block2\")\n",
    "        # middle\n",
    "        print(f\"h shape is {len(h)} {h[0].shape}\")\n",
    "        h = hs[-1]\n",
    "        h = self.mid.block_1(h, temb)\n",
    "        h = self.mid.attn_1(h)\n",
    "        h = self.mid.block_2(h, temb)\n",
    "        print(f\"h shape is {len(h)} {h[0].shape}\")\n",
    "        print(f\"Now computing end norn_out->attn1->conv_out\")\n",
    "        # end\n",
    "        print(f\"h shape is {len(h)} {h[0].shape}\")\n",
    "        h = self.norm_out(h)\n",
    "        h = nonlinearity(h)\n",
    "        h = self.conv_out(h)\n",
    "        print(f\"h shape is {len(h)} {h[0].shape}\")\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making attention of type 'vanilla-xformers' with 16 in_channels\n",
      "building MemoryEfficientAttnBlock with 16 in_channels...\n",
      "Down is:\n",
      "After down sampling, hs is 1 torch.Size([10, 2, 640, 640])\n",
      "level 1/4\n",
      "block 1/2\n",
      "Now in a ResNet. We do norm1->nonlinear->conv1->norm2->nonlinear->dropout->conv2->x+h\n",
      "Input shape is torch.Size([10, 2, 640, 640])\n",
      "Output shape is torch.Size([10, 2, 640, 640])\n",
      "block 2/2\n",
      "Now in a ResNet. We do norm1->nonlinear->conv1->norm2->nonlinear->dropout->conv2->x+h\n",
      "Input shape is torch.Size([10, 2, 640, 640])\n",
      "Output shape is torch.Size([10, 2, 640, 640])\n",
      "level 2/4\n",
      "block 1/2\n",
      "Now in a ResNet. We do norm1->nonlinear->conv1->norm2->nonlinear->dropout->conv2->x+h\n",
      "Input shape is torch.Size([10, 2, 320, 320])\n",
      "Output shape is torch.Size([10, 4, 320, 320])\n",
      "block 2/2\n",
      "Now in a ResNet. We do norm1->nonlinear->conv1->norm2->nonlinear->dropout->conv2->x+h\n",
      "Input shape is torch.Size([10, 4, 320, 320])\n",
      "Output shape is torch.Size([10, 4, 320, 320])\n",
      "level 3/4\n",
      "block 1/2\n",
      "Now in a ResNet. We do norm1->nonlinear->conv1->norm2->nonlinear->dropout->conv2->x+h\n",
      "Input shape is torch.Size([10, 4, 160, 160])\n",
      "Output shape is torch.Size([10, 8, 160, 160])\n",
      "block 2/2\n",
      "Now in a ResNet. We do norm1->nonlinear->conv1->norm2->nonlinear->dropout->conv2->x+h\n",
      "Input shape is torch.Size([10, 8, 160, 160])\n",
      "Output shape is torch.Size([10, 8, 160, 160])\n",
      "level 4/4\n",
      "block 1/2\n",
      "Now in a ResNet. We do norm1->nonlinear->conv1->norm2->nonlinear->dropout->conv2->x+h\n",
      "Input shape is torch.Size([10, 8, 80, 80])\n",
      "Output shape is torch.Size([10, 16, 80, 80])\n",
      "block 2/2\n",
      "Now in a ResNet. We do norm1->nonlinear->conv1->norm2->nonlinear->dropout->conv2->x+h\n",
      "Input shape is torch.Size([10, 16, 80, 80])\n",
      "Output shape is torch.Size([10, 16, 80, 80])\n",
      "Now computing middle block1->attn1->block2\n",
      "h shape is 10 torch.Size([16, 80, 80])\n",
      "Now in a ResNet. We do norm1->nonlinear->conv1->norm2->nonlinear->dropout->conv2->x+h\n",
      "Input shape is torch.Size([10, 16, 80, 80])\n",
      "Output shape is torch.Size([10, 16, 80, 80])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (12800x80 and 16x512)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 19\u001b[0m\n\u001b[1;32m      3\u001b[0m encoder \u001b[38;5;241m=\u001b[39m Encoder(\n\u001b[1;32m      4\u001b[0m     ch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,  \u001b[38;5;66;03m# Base channel dimensionality\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     out_ch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# This parameter might be unused based on your class definition\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     attn_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvanilla\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Type of attention, if used\u001b[39;00m\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     18\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m640\u001b[39m, \u001b[38;5;241m640\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/pmglocal/ty2514/GET_STARTED/mambaforge/get_started/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/pmglocal/ty2514/GET_STARTED/mambaforge/get_started/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 96\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     94\u001b[0m h \u001b[38;5;241m=\u001b[39m hs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     95\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmid\u001b[38;5;241m.\u001b[39mblock_1(h, temb)\n\u001b[0;32m---> 96\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmid\u001b[38;5;241m.\u001b[39mblock_2(h, temb)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh shape is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(h)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/pmglocal/ty2514/GET_STARTED/mambaforge/get_started/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/pmglocal/ty2514/GET_STARTED/mambaforge/get_started/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/pmglocal/ty2514/GET_STARTED/get_model/get_model/model/sdvae.py:351\u001b[0m, in \u001b[0;36mCrossAttention.forward\u001b[0;34m(self, x, context, mask)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    349\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads\n\u001b[0;32m--> 351\u001b[0m     q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_q\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    352\u001b[0m     context \u001b[38;5;241m=\u001b[39m default(context, x)\n\u001b[1;32m    353\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_k(context)\n",
      "File \u001b[0;32m/pmglocal/ty2514/GET_STARTED/mambaforge/get_started/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/pmglocal/ty2514/GET_STARTED/mambaforge/get_started/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/pmglocal/ty2514/GET_STARTED/mambaforge/get_started/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (12800x80 and 16x512)"
     ]
    }
   ],
   "source": [
    "from sdvae import MemoryEfficientAttnBlock,Normalize,Downsample,make_attn,ResnetBlock\n",
    "\n",
    "encoder = Encoder(\n",
    "    ch=2,  # Base channel dimensionality\n",
    "    out_ch=None,  # This parameter might be unused based on your class definition\n",
    "    ch_mult=(1, 2, 4, 8),  # Channel multipliers for each level\n",
    "    num_res_blocks=2,  # Number of residual blocks per level\n",
    "    attn_resolutions=(20, 40),  # Resolutions to apply attention, adjust based on your needs\n",
    "    dropout=0.1,  # Dropout rate for regularization\n",
    "    resamp_with_conv=True,  # Use convolutional downsampling\n",
    "    in_channels=1,  # Match the input channel size\n",
    "    resolution=640,  # Input resolution (for understanding, not a direct parameter)\n",
    "    z_channels=128,  # Half the desired latent space dimensionality if double_z=True\n",
    "    double_z=True,  # Output both mean and variance for the latent distribution\n",
    "    use_linear_attn=False,  # Based on preference and model complexity\n",
    "    attn_type=\"vanilla\"  # Type of attention, if used\n",
    ")\n",
    "x = torch.randn(10, 1, 640, 640)\n",
    "encoder(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
